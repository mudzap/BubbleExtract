% Created 2021-04-18 dom 00:49
% Intended LaTeX compiler: pdflatex
\documentclass[letter, 10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[spanish]{babel}
\usepackage{times}
\usepackage[spanish]{babel}
\usepackage{microtype}
\usepackage{inconsolata}
\author{Iván Guillermo Peña Flores}
\date{\today}
\title{Documentación proyecto 1}
\hypersetup{
 pdfauthor={Iván Guillermo Peña Flores},
 pdftitle={Documentación proyecto 1},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.2 (Org mode 9.4.4)}, 
 pdflang={Spanish}}
\begin{document}

\maketitle
\tableofcontents


\section{Propuesta}
\label{sec:org6243c55}

Motor OCR para comics japoneses para transcibir estos a un formato estandar.

Existen algunas ventajas:
\begin{itemize}
\item Es posible adquirir una gran cantidad de datos con facilidad
\item Las condiciones son relativamente ideales (para la mayoria de los scans)
\end{itemize}

Las desventajas serian:
\begin{itemize}
\item El texto no siempre se encuentra en burbujas
\item El estilo varia de artista a artista
\item Onomatopeias son tipicamente completamente diferentes al texto "normal"
\item Muchos casos de estilización, lectura de izquierda a derecha, en estos casos es tipico necesitar realizar ajustes manuales
\item Tesseract ya esta muy completo y es dificil ofrecer una alternativa, sin embargo, como API, puede ofrecer cierta flexibilidad e incluso puede ser entrenado.
\end{itemize}

\subsection{Propuesta 1}
\label{sec:org861da79}

Se considero inicialmente el uso de dos redes neuronales secuenciales, una para identificar texto y su orientación, y la segunda, para transcribirlo caracter por caracter, la justificación de esto, es en acelerar el entrenamiento, y posiblemente, el tamaño de las redes.
Se infieren estas cosas considerando lo siguiente:

\begin{itemize}
\item La extracción de caracteristicas 'finas' en un contexto general, implica la necesidad de una mayor cantidad de filtros, y se considera que es posible que sesgue y lleve a la identificación de falsos positivos.
\item Al ser este un caso altamente especializado, el uso de redes convolucionales especializadas no es un problema, sino algo deseable.
\end{itemize}

\subsection{Propuesta 2}
\label{sec:orgb797ea5}

Lamentablemente, tesseract es una herramienta muy versatil para el OCR, siendo capaz de todo lo anterior mencionado, sin embargo, todavia prevalecen algunos problemas:

\begin{itemize}
\item Uso de ambos texto vertical y horizontal
\item Texto altamente estilizado
\end{itemize}

En este momento no se sabe como lidiar con el texto altamente estilizado, sin embargo, un factor de gran importancia, que puede facilitar su identificación es que este suele estar limitado a katakana y rara vez a hiragana. Esto reduce considerablemente el numero de clases a las que puede realizarse la clasificación. De ser posible, lo mejor seria trabajarlo con tesseract, sin embargo este parece estar diseñado para fuentes nada mas.

\subsection{Propuesta 3}
\label{sec:org7e5605c}

Tesseract no es tan bueno como lo suponia, inlcuso identificar burbujas es una ventaja sobre tesseract puro.

Para la identificación de burbujas de dialogo, se propone un filtro laplaciano, seguido por binarización y dilatación.

Despues de esto, realizar un muestreo distribuido linearmente, y construir una mascarilla de las zonas negras rellenadas, de las cuales, a través de su histograma en la imagen original determinaran la posición, orientiación, y si es texto o no.

la razon por la que se utilizo un filtro laplaciano en vez de otro algoritmo de detección de bordes, es que no se busca detectar bordes, sino establecer regiones claramentet separables, también da la ventaja que si es un escaneo de un volumen sin quitarle las paginas, se elimina l

\section{Dependencias}
\label{sec:org94f940b}

Se pueden instalar las dependencias de forma rapida con pip y un package manager:

\begin{verbatim}
pip install tesserocr
sudo apt install libtesseract* tesseract-ocr-script-jpan*\
tesseract-ocr-jpn* libleptonica*
\end{verbatim}

El resto de las dependencias (tesseract-ocr, tesseract-ocr-eng\ldots{}) se instalan automaticamente.

IEEE

Practica
\begin{itemize}
\item Opción 2:
Propuestas a mejorar a futuro, si no sirve
Que se ha hecho?

Para pruebas, bajar la maquina virtual (ROS)
\url{https://www.cscjournals.org/manuscript/Journals/IJIP/Volume4/Issue6/IJIP-290.pdf}

Observaciones: Muy similar a mi propuesta, no se realiza detección de bordes previa, pero si se utiliza un operador morfologico. Aqui, se utiliza la relación entre la dimensión horizontal y vertical del bloque de texto para determinar si es o no.

El papel es relativamente viejo, asi que no maneja tecnicas de aprendizaje de maquina, de las cuales nosotros si podemos hacer uso.

Es posible probar con ambos metodos para la detección de burbujas (que dio buenos resultados en el papel), y luego implementar una red neuronal para detectar las caracteristicas de esta, con un preprocesamiento para asegurar que se mantengan 'text-like characteristics', asi luego hacer uso de un OCR tradicional como tesseract.
\end{itemize}

\begin{center}
\includegraphics[width=1.5in]{./img_threshold.jpg}
\includegraphics[width=1.5in]{./img_canny.jpg}
\includegraphics[width=1.5in]{./img_laplacian.jpg}
\end{center}


\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./example_no_text.png}
\caption{\label{fig:org2014c81}HOLA!}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./example_no_hor.png}
\caption{\label{fig:org1900f47}HOR}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./example_no_vert.png}
\caption{\label{fig:org9381df1}VER}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./example_page.jpg}
\caption{\label{fig:orgc5fe822}EXAMPLE}
\end{figure}



\begin{center}
\includegraphics[width=4in]{./50_epochs_weights.png}
\label{org50f7a1e}
\end{center}

\begin{center}
\includegraphics[width=4in]{./150_epochs_weights.png}
\end{center}

\begin{center}
\includegraphics[width=4in]{./1000_epochs_weights.png}
\end{center}


\begin{verbatim}
import glob
import os
import numpy as np
import tensorflow as tf
import cv2
import matplotlib.pyplot as plt

import get_data as gd
from tensorflow.keras import preprocessing
from tensorflow import keras

# Cargar imagenes
image_set_gs = []
for file in glob.glob("examples_post/*.jpg"):
    img = cv2.imread(file)
    image_set_gs.append(
	cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))
    print("Reading: " + file)

# Hacerlas en una matriz de numpy
np_filter = np.array(image_set_gs, dtype=np.object)
np_original = np.copy(np_filter)

# Filtrarlas por cualquier metodo
gd.filter_method_canny(np_filter, 3)

bubble_set = []
res_xy = (24, 32)

gd.get_speech_bubble_candidates(
    np_original, np_filter, bubble_set,
    res_xy, 127)
bubble_set = np.array(bubble_set)
bubble_set = bubble_set

#Carga la red
model = keras.models.load_model("models/trained_model_50")
model.summary()

#Muestra los pesos de la capa convolucional
layer = model.get_layer("conv2d")
w_t = layer.get_weights()[0]

norm_val = 1/np.amax(w_t)

for k in range(0, w_t.shape[3]):
    plt.subplot(4, 8, k+1)
    plt.imshow(w_t[:,:,:,k]*norm_val)
plt.show()

#Clasifica, y guarda solamente bloques de
#texto vertical y horizontal
i = 0
for img in bubble_set:
    t_img = cv2.resize(img, (50, 50))
    t_img = np.reshape(t_img, (-1, *t_img.shape))
    pred_vec = model.predict([t_img])
    pred_class = np.argmax(pred_vec)
    if(pred_class != 0):
	out_img = img[:,:,1]
	cv2.imwrite("examples_post/output/a" + str(i) + ".png", out_img)
	i += 1

print("EOP")

\end{verbatim}
\end{document}
